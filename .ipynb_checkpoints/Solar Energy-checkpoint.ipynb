{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b289e248",
   "metadata": {},
   "source": [
    "# TAAK Data Prasentation: Zonne-energie op basis van het weer\n",
    "In dit datavisualisatie project wordt de correlatie tussen de productie van elektrischiteit met zonnepanelen en het weer op dat moment onderzocht. Op het einde wordt er een conclusie getrokken waarin dit zal worden aangetoond of weerlegd. Er wordt met Spark (PySpark) gewerkt in een Jupyter Notebook om de data te preprocessen en te analyseren.\n",
    "\n",
    "De data is beperkt tot Canada gezien ik geen andere kwalitatieve data kon vinden waar ook kwalitatieve historische weerdata voor te vinden was.\n",
    "\n",
    "De datasets zijn terug te vinden op onderstaande links.\n",
    "- weer data: https://calgary.weatherstats.ca/download.html\n",
    "https://climatedata.ca/download/\n",
    "\n",
    "b optie data voor dit project: https://www.kaggle.com/datasets/anikannal/solar-power-generation-data/data\n",
    "- solar production: https://www.kaggle.com/datasets/ivnlee/solar-energy-production"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4639ac",
   "metadata": {},
   "source": [
    "## Imports en spark innitialiseren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7dc6808e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "from pyspark.sql.functions import col, unix_timestamp, from_unixtime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "29735408",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local\").appName(\"DataPresentationTaak\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4a7c554b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://localhost:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>DataPresentationTaak</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x22c47055c70>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d52f9a",
   "metadata": {},
   "source": [
    "## 1 Data inladen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e70a7907",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_energy = \"../SolarEnergyData/Solar_Energy_Production.csv\"\n",
    "data_weather = \"../SolarEnergyData/weatherstats_calgary_dailySince2015.csv\"\n",
    "\n",
    "df_energy = spark.read.format(\"csv\").option(\"header\",\"true\").option(\"inferSchema\",\"true\").option(\"mode\",\"failfast\").load(data_energy)\n",
    "df_weather = spark.read.format(\"csv\").option(\"header\",\"true\").option(\"inferSchema\",\"true\").option(\"mode\",\"failfast\").load(data_weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad98625c",
   "metadata": {},
   "source": [
    "## 2 Data exploratory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c0bcbf5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+-------------+--------------------+------+--------------------+----------------+--------------------+\n",
      "|                name|    id|      address|                date|   kWh|          public_url|installationDate|                 uid|\n",
      "+--------------------+------+-------------+--------------------+------+--------------------+----------------+--------------------+\n",
      "|Calgary Fire Hall...|314106|1212 42 AV SE|2017/09/11 08:00:...|  1.13|https://monitorin...|      2016/11/07|3141062017-09-11 ...|\n",
      "|Calgary Fire Hall...|314106|1212 42 AV SE|2017/09/11 09:00:...|  2.34|https://monitorin...|      2016/11/07|3141062017-09-11 ...|\n",
      "|Calgary Fire Hall...|314106|1212 42 AV SE|2017/09/11 10:00:...| 3.656|https://monitorin...|      2016/11/07|3141062017-09-11 ...|\n",
      "|Calgary Fire Hall...|314106|1212 42 AV SE|2017/09/11 11:00:...| 4.577|https://monitorin...|      2016/11/07|3141062017-09-11 ...|\n",
      "|Calgary Fire Hall...|314106|1212 42 AV SE|2017/09/11 12:00:...| 6.506|https://monitorin...|      2016/11/07|3141062017-09-11 ...|\n",
      "|Calgary Fire Hall...|314106|1212 42 AV SE|2017/09/11 01:00:...| 7.031|https://monitorin...|      2016/11/07|3141062017-09-11 ...|\n",
      "|Calgary Fire Hall...|314106|1212 42 AV SE|2017/09/11 02:00:...| 9.218|https://monitorin...|      2016/11/07|3141062017-09-11 ...|\n",
      "|Calgary Fire Hall...|314106|1212 42 AV SE|2017/09/11 03:00:...| 9.018|https://monitorin...|      2016/11/07|3141062017-09-11 ...|\n",
      "|Calgary Fire Hall...|314106|1212 42 AV SE|2017/09/11 04:00:...| 5.266|https://monitorin...|      2016/11/07|3141062017-09-11 ...|\n",
      "|Calgary Fire Hall...|314106|1212 42 AV SE|2017/09/11 05:00:...| 2.579|https://monitorin...|      2016/11/07|3141062017-09-11 ...|\n",
      "|Calgary Fire Hall...|314106|1212 42 AV SE|2017/09/11 06:00:...| 3.118|https://monitorin...|      2016/11/07|3141062017-09-11 ...|\n",
      "|Calgary Fire Hall...|314106|1212 42 AV SE|2017/09/11 07:00:...| 0.738|https://monitorin...|      2016/11/07|3141062017-09-11 ...|\n",
      "|Calgary Fire Hall...|314106|1212 42 AV SE|2017/09/12 07:00:...| 0.134|https://monitorin...|      2016/11/07|3141062017-09-12 ...|\n",
      "|Calgary Fire Hall...|314106|1212 42 AV SE|2017/09/12 08:00:...| 1.231|https://monitorin...|      2016/11/07|3141062017-09-12 ...|\n",
      "|Calgary Fire Hall...|314106|1212 42 AV SE|2017/09/12 09:00:...| 4.096|https://monitorin...|      2016/11/07|3141062017-09-12 ...|\n",
      "|Calgary Fire Hall...|314106|1212 42 AV SE|2017/09/12 10:00:...| 6.449|https://monitorin...|      2016/11/07|3141062017-09-12 ...|\n",
      "|Calgary Fire Hall...|314106|1212 42 AV SE|2017/09/12 11:00:...| 9.652|https://monitorin...|      2016/11/07|3141062017-09-12 ...|\n",
      "|Calgary Fire Hall...|314106|1212 42 AV SE|2017/09/12 12:00:...|11.191|https://monitorin...|      2016/11/07|3141062017-09-12 ...|\n",
      "|Calgary Fire Hall...|314106|1212 42 AV SE|2017/09/12 01:00:...| 8.344|https://monitorin...|      2016/11/07|3141062017-09-12 ...|\n",
      "|Calgary Fire Hall...|314106|1212 42 AV SE|2017/09/12 02:00:...|11.703|https://monitorin...|      2016/11/07|3141062017-09-12 ...|\n",
      "+--------------------+------+-------------+--------------------+------+--------------------+----------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_energy.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8174adce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "258423"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_energy.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b52d8ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06df050f",
   "metadata": {},
   "source": [
    "De energie-productie (df_energy_df) dataset bevat 258423 records en de weer-dataset (df_weather) bevat er 10000. Bij 'df_energy' gaan we algemener kijk en groeperen per dag, omdat er helaas geen data per uur terug te vinden was over deze periode. Bij 'df_weather' vallen er nog een heel deel records af die buiten het bereik van 'df_energy' liggen. Zie Cleaning stap 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "44944a6c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__call__() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [51]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# create schema (checken of nog nodig of niet)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m schema \u001b[38;5;241m=\u001b[39m StructType([\n\u001b[1;32m----> 3\u001b[0m     StructField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mIntegerType\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m      4\u001b[0m     StructField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol2\u001b[39m\u001b[38;5;124m\"\u001b[39m, IntegerType(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m      5\u001b[0m     StructField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol3\u001b[39m\u001b[38;5;124m\"\u001b[39m, IntegerType(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m      6\u001b[0m     StructField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol4\u001b[39m\u001b[38;5;124m\"\u001b[39m, IntegerType(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m      7\u001b[0m     StructField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol5\u001b[39m\u001b[38;5;124m\"\u001b[39m, IntegerType(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m      8\u001b[0m     StructField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol6\u001b[39m\u001b[38;5;124m\"\u001b[39m, IntegerType(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m      9\u001b[0m     StructField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol7\u001b[39m\u001b[38;5;124m\"\u001b[39m, IntegerType(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m     10\u001b[0m     StructField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol8\u001b[39m\u001b[38;5;124m\"\u001b[39m, IntegerType(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m     11\u001b[0m     \n\u001b[0;32m     12\u001b[0m ])\n",
      "\u001b[1;31mTypeError\u001b[0m: __call__() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "# create schema (checken of nog nodig of niet)\n",
    "schema = StructType([\n",
    "    StructField(\"col1\", IntegerType(0), True),\n",
    "    StructField(\"col2\", IntegerType(0), True),\n",
    "    StructField(\"col3\", IntegerType(0), True),\n",
    "    StructField(\"col4\", IntegerType(0), True),\n",
    "    StructField(\"col5\", IntegerType(0), True),\n",
    "    StructField(\"col6\", IntegerType(0), True),\n",
    "    StructField(\"col7\", IntegerType(0), True),\n",
    "    StructField(\"col8\", IntegerType(0), True),\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dd12a4f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[PATH_NOT_FOUND] Path does not exist: file:/C:/Users/jarno/SCHOOL Data Presentation/input/airbnbopendata/Airbnb_Open_Data.csv.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [52]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#tests en backup code\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df_energy \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mheader\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minferSchema\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmode\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfailfast\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../input/airbnbopendata/Airbnb_Open_Data.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# csv inladen\u001b[39;00m\n\u001b[0;32m      5\u001b[0m energy \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39mread\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mschema(schema)\u001b[38;5;241m.\u001b[39moption(data_energy, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mload()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyspark\\sql\\readwriter.py:307\u001b[0m, in \u001b[0;36mDataFrameReader.load\u001b[1;34m(self, path, format, schema, **options)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    309\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(path) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mAnalysisException\u001b[0m: [PATH_NOT_FOUND] Path does not exist: file:/C:/Users/jarno/SCHOOL Data Presentation/input/airbnbopendata/Airbnb_Open_Data.csv."
     ]
    }
   ],
   "source": [
    "#tests en backup code\n",
    "df_energy = spark.read.format(\"csv\").option(\"header\",\"true\").option(\"inferSchema\",\"true\").option(\"mode\",\"failfast\").load(\"../input/airbnbopendata/Airbnb_Open_Data.csv\")\n",
    "\n",
    "# csv inladen\n",
    "energy = spark.read.format(\"csv\").schema(schema).option(data_energy, \"test.csv\").load()\n",
    "weather = spark.read.format(\"csv\").schema(schema).option(\"path\", \"test.csv\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbb1a02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17afdd3f",
   "metadata": {},
   "source": [
    "## 3 cleaning & preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf180a0",
   "metadata": {},
   "source": [
    "### data uit df_energy groeperen per dag\n",
    "Er wordt verder gerekend met de gemiddelde kWh per dag in df_energy, gezien we niet van elk uur weerdata ter beschikking hebben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "26afcecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, name: string, id: string, address: string, date: string, kWh: string, public_url: string, installationDate: string, uid: string]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_energy.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cc1489ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                date|\n",
      "+--------------------+\n",
      "|2017/09/11 08:00:...|\n",
      "|2017/09/11 09:00:...|\n",
      "|2017/09/11 10:00:...|\n",
      "|2017/09/11 11:00:...|\n",
      "|2017/09/11 12:00:...|\n",
      "|2017/09/11 01:00:...|\n",
      "|2017/09/11 02:00:...|\n",
      "|2017/09/11 03:00:...|\n",
      "|2017/09/11 04:00:...|\n",
      "|2017/09/11 05:00:...|\n",
      "|2017/09/11 06:00:...|\n",
      "|2017/09/11 07:00:...|\n",
      "|2017/09/12 07:00:...|\n",
      "|2017/09/12 08:00:...|\n",
      "|2017/09/12 09:00:...|\n",
      "|2017/09/12 10:00:...|\n",
      "|2017/09/12 11:00:...|\n",
      "|2017/09/12 12:00:...|\n",
      "|2017/09/12 01:00:...|\n",
      "|2017/09/12 02:00:...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_energy.createOrReplaceTempView(\"energy\")\n",
    "\n",
    "results = spark.sql(\"SELECT date FROM energy\")\n",
    "results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8356b775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|     date2|\n",
      "+----------+\n",
      "|2017-09-11|\n",
      "|2017-09-11|\n",
      "|2017-09-11|\n",
      "|2017-09-11|\n",
      "|2017-09-11|\n",
      "|2017-09-11|\n",
      "|2017-09-11|\n",
      "|2017-09-11|\n",
      "|2017-09-11|\n",
      "|2017-09-11|\n",
      "|2017-09-11|\n",
      "|2017-09-11|\n",
      "|2017-09-12|\n",
      "|2017-09-12|\n",
      "|2017-09-12|\n",
      "|2017-09-12|\n",
      "|2017-09-12|\n",
      "|2017-09-12|\n",
      "|2017-09-12|\n",
      "|2017-09-12|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df_energy.withColumn(\"date2\", from_unixtime(unix_timestamp(col(\"date\"), 'yyyy/MM/dd hh:mm:ss a')).cast(\"date\"))\n",
    "\n",
    "df.select(\"date2\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b392902c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n",
      "|     date2|          avg(kWh)|\n",
      "+----------+------------------+\n",
      "|2015-09-01|28.601300000000002|\n",
      "|2015-09-02| 32.45933333333333|\n",
      "|2015-09-03|30.852666666666657|\n",
      "|2015-09-04|            5.1224|\n",
      "|2015-09-05|4.9174736842105276|\n",
      "|2015-09-06|           18.3813|\n",
      "|2015-09-07|30.262947368421052|\n",
      "|2015-09-08|           24.4907|\n",
      "|2015-09-09|           36.6001|\n",
      "|2015-09-10|  33.0881052631579|\n",
      "|2015-09-11| 45.54736842105263|\n",
      "|2015-09-12| 44.59063157894737|\n",
      "|2015-09-13|13.285210526315788|\n",
      "|2015-09-14|  5.36278947368421|\n",
      "|2015-09-15| 32.56542105263158|\n",
      "|2015-09-16| 35.77613333333333|\n",
      "|2015-09-17| 50.94357142857143|\n",
      "|2015-09-18| 50.00066666666666|\n",
      "|2015-09-21| 45.08325000000001|\n",
      "|2015-09-22|60.640538461538455|\n",
      "+----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_energy = df_energy.withColumn(\"date2\", from_unixtime(unix_timestamp(col(\"date\"), 'yyyy/MM/dd hh:mm:ss a')).cast(\"date\"))\n",
    "# Group by the date and calculate the average temperature for each day\n",
    "result_df = df_temp.groupBy(\"date2\").agg({\"kWh\": \"avg\"}).orderBy(\"date2\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977ce945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c371129c",
   "metadata": {},
   "source": [
    "### data buiten bereik filteren\n",
    "Dagen uit df_weather verwijderen die buiten het bereik van df_energy vallen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02df118b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_energy.select(\"date\").orderBy(\"date\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "be96605f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|      Date|\n",
      "+----------+\n",
      "|2023-11-28|\n",
      "|2023-11-27|\n",
      "|2023-11-26|\n",
      "|2023-11-25|\n",
      "|2023-11-24|\n",
      "|2023-11-23|\n",
      "|2023-11-22|\n",
      "|2023-11-21|\n",
      "|2023-11-20|\n",
      "|2023-11-19|\n",
      "|2023-11-18|\n",
      "|2023-11-17|\n",
      "|2023-11-16|\n",
      "|2023-11-15|\n",
      "|2023-11-14|\n",
      "|2023-11-13|\n",
      "|2023-11-12|\n",
      "|2023-11-11|\n",
      "|2023-11-10|\n",
      "|2023-11-09|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_weather.select(\"Date\").orderBy(\"date\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "abbe9fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, max_temperature: string, avg_hourly_temperature: string, avg_temperature: string, min_temperature: string, max_humidex: string, min_windchill: string, max_relative_humidity: string, avg_hourly_relative_humidity: string, avg_relative_humidity: string, min_relative_humidity: string, max_dew_point: string, avg_hourly_dew_point: string, avg_dew_point: string, min_dew_point: string, max_wind_speed: string, avg_hourly_wind_speed: string, avg_wind_speed: string, min_wind_speed: string, max_wind_gust: string, wind_gust_dir_10s: string, max_pressure_sea: string, avg_hourly_pressure_sea: string, avg_pressure_sea: string, min_pressure_sea: string, max_pressure_station: string, avg_hourly_pressure_station: string, avg_pressure_station: string, min_pressure_station: string, max_visibility: string, avg_hourly_visibility: string, avg_visibility: string, min_visibility: string, max_health_index: string, avg_hourly_health_index: string, avg_health_index: string, min_health_index: string, heatdegdays: string, cooldegdays: string, growdegdays_5: string, growdegdays_7: string, growdegdays_10: string, precipitation: string, rain: string, snow: string, snow_on_ground: string, sunrise_unixtime: string, sunrise_f: string, sunset_unixtime: string, sunset_f: string, daylight: string, min_uv_forecast: string, max_uv_forecast: string, min_high_temperature_forecast: string, max_high_temperature_forecast: string, min_low_temperature_forecast: string, max_low_temperature_forecast: string, solar_radiation: string, max_cloud_cover_4: string, avg_hourly_cloud_cover_4: string, avg_cloud_cover_4: string, min_cloud_cover_4: string, max_cloud_cover_8: string, avg_hourly_cloud_cover_8: string, avg_cloud_cover_8: string, min_cloud_cover_8: string, max_cloud_cover_10: string, avg_hourly_cloud_cover_10: string, avg_cloud_cover_10: string, min_cloud_cover_10: string]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dagen buiten bereik verwijderen\n",
    "df_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3443c06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+---------------+\n",
      "|     date2|   kWh|avg_temperature|\n",
      "+----------+------+---------------+\n",
      "|2015-09-01|27.805|          14.64|\n",
      "|2015-09-01|30.559|          14.64|\n",
      "|2015-09-01|23.613|          14.64|\n",
      "|2015-09-01|15.257|          14.64|\n",
      "|2015-09-01| 7.896|          14.64|\n",
      "|2015-09-01| 1.885|          14.64|\n",
      "|2015-09-01|41.066|          14.64|\n",
      "|2015-09-01|57.844|          14.64|\n",
      "|2015-09-01|48.606|          14.64|\n",
      "|2015-09-01|31.482|          14.64|\n",
      "|2015-09-02|60.377|          15.45|\n",
      "|2015-09-02|  0.01|          15.45|\n",
      "|2015-09-02|64.576|          15.45|\n",
      "|2015-09-02|36.579|          15.45|\n",
      "|2015-09-02| 18.23|          15.45|\n",
      "|2015-09-02|16.406|          15.45|\n",
      "|2015-09-02|35.959|          15.45|\n",
      "|2015-09-02| 0.006|          15.45|\n",
      "|2015-09-02|57.311|          15.45|\n",
      "|2015-09-02| 7.912|          15.45|\n",
      "+----------+------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Alias the DataFrames\n",
    "energy = df_energy.alias(\"df_energy\")\n",
    "weer = df_weather.alias(\"df_weather\")\n",
    "\n",
    "# Perform the inner join based on the 'date' column\n",
    "joined_df = energy.join(weer, energy['date2'] == weer['Date'], 'left')\n",
    "\n",
    "\n",
    "# Show the result\n",
    "joined_df.select(energy['date2'], energy['kWh'], weer['avg_temperature']).orderBy(\"date2\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4b351d",
   "metadata": {},
   "source": [
    "### joinen op basis van datum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "81cd3e22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "258423"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the result\n",
    "joined_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a43e92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
