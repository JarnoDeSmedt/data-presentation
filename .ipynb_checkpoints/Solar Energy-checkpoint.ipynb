{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b289e248",
   "metadata": {},
   "source": [
    "# TAAK Data Prasentation: Zonne-energie op basis van het weer\n",
    "In dit datavisualisatie project wordt de correlatie tussen de productie van elektrischiteit met zonnepanelen en het weer op dat moment onderzocht. Op het einde wordt er een conclusie getrokken waarin dit zal worden aangetoond of weerlegd. Er wordt met Spark (PySpark) gewerkt in een Jupyter Notebook om de data te preprocessen en te analyseren.\n",
    "\n",
    "De data is beperkt tot Canada gezien ik geen andere kwalitatieve data kon vinden waar ook kwalitatieve historische weerdata voor te vinden was.\n",
    "\n",
    "De datasets zijn terug te vinden op onderstaande links.\n",
    "- weer data: https://calgary.weatherstats.ca/download.html\n",
    "https://climatedata.ca/download/\n",
    "\n",
    "b optie data voor dit project: https://www.kaggle.com/datasets/anikannal/solar-power-generation-data/data\n",
    "- solar production: https://www.kaggle.com/datasets/ivnlee/solar-energy-production"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4639ac",
   "metadata": {},
   "source": [
    "## Imports en spark innitialiseren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7dc6808e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "from pyspark.sql.functions import col, unix_timestamp, from_unixtime, to_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "29735408",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local\").appName(\"DataPresentationTaak\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4a7c554b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.59:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>DataPresentationTaak</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x19e17cbbc70>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d52f9a",
   "metadata": {},
   "source": [
    "## 1 Data inladen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e70a7907",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_energy = \"../SolarEnergyData/Solar_Energy_Production.csv\"\n",
    "data_weather = \"../SolarEnergyData/weatherstats_calgary_dailySince2015.csv\"\n",
    "\n",
    "df_energy = spark.read.format(\"csv\").option(\"header\",\"true\").option(\"inferSchema\",\"true\").option(\"mode\",\"failfast\").load(data_energy)\n",
    "df_weather = spark.read.format(\"csv\").option(\"header\",\"true\").option(\"inferSchema\",\"true\").option(\"mode\",\"failfast\").load(data_weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad98625c",
   "metadata": {},
   "source": [
    "## 2 Data exploratory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c0bcbf5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+-------------+--------------------+------+--------------------+----------------+--------------------+\n",
      "|                name|    id|      address|                date|   kWh|          public_url|installationDate|                 uid|\n",
      "+--------------------+------+-------------+--------------------+------+--------------------+----------------+--------------------+\n",
      "|Calgary Fire Hall...|314106|1212 42 AV SE|2017/09/11 08:00:...|  1.13|https://monitorin...|      2016/11/07|3141062017-09-11 ...|\n",
      "|Calgary Fire Hall...|314106|1212 42 AV SE|2017/09/11 09:00:...|  2.34|https://monitorin...|      2016/11/07|3141062017-09-11 ...|\n",
      "|Calgary Fire Hall...|314106|1212 42 AV SE|2017/09/11 10:00:...| 3.656|https://monitorin...|      2016/11/07|3141062017-09-11 ...|\n",
      "|Calgary Fire Hall...|314106|1212 42 AV SE|2017/09/11 11:00:...| 4.577|https://monitorin...|      2016/11/07|3141062017-09-11 ...|\n",
      "|Calgary Fire Hall...|314106|1212 42 AV SE|2017/09/11 12:00:...| 6.506|https://monitorin...|      2016/11/07|3141062017-09-11 ...|\n",
      "|Calgary Fire Hall...|314106|1212 42 AV SE|2017/09/11 01:00:...| 7.031|https://monitorin...|      2016/11/07|3141062017-09-11 ...|\n",
      "|Calgary Fire Hall...|314106|1212 42 AV SE|2017/09/11 02:00:...| 9.218|https://monitorin...|      2016/11/07|3141062017-09-11 ...|\n",
      "|Calgary Fire Hall...|314106|1212 42 AV SE|2017/09/11 03:00:...| 9.018|https://monitorin...|      2016/11/07|3141062017-09-11 ...|\n",
      "|Calgary Fire Hall...|314106|1212 42 AV SE|2017/09/11 04:00:...| 5.266|https://monitorin...|      2016/11/07|3141062017-09-11 ...|\n",
      "|Calgary Fire Hall...|314106|1212 42 AV SE|2017/09/11 05:00:...| 2.579|https://monitorin...|      2016/11/07|3141062017-09-11 ...|\n",
      "|Calgary Fire Hall...|314106|1212 42 AV SE|2017/09/11 06:00:...| 3.118|https://monitorin...|      2016/11/07|3141062017-09-11 ...|\n",
      "|Calgary Fire Hall...|314106|1212 42 AV SE|2017/09/11 07:00:...| 0.738|https://monitorin...|      2016/11/07|3141062017-09-11 ...|\n",
      "|Calgary Fire Hall...|314106|1212 42 AV SE|2017/09/12 07:00:...| 0.134|https://monitorin...|      2016/11/07|3141062017-09-12 ...|\n",
      "|Calgary Fire Hall...|314106|1212 42 AV SE|2017/09/12 08:00:...| 1.231|https://monitorin...|      2016/11/07|3141062017-09-12 ...|\n",
      "|Calgary Fire Hall...|314106|1212 42 AV SE|2017/09/12 09:00:...| 4.096|https://monitorin...|      2016/11/07|3141062017-09-12 ...|\n",
      "|Calgary Fire Hall...|314106|1212 42 AV SE|2017/09/12 10:00:...| 6.449|https://monitorin...|      2016/11/07|3141062017-09-12 ...|\n",
      "|Calgary Fire Hall...|314106|1212 42 AV SE|2017/09/12 11:00:...| 9.652|https://monitorin...|      2016/11/07|3141062017-09-12 ...|\n",
      "|Calgary Fire Hall...|314106|1212 42 AV SE|2017/09/12 12:00:...|11.191|https://monitorin...|      2016/11/07|3141062017-09-12 ...|\n",
      "|Calgary Fire Hall...|314106|1212 42 AV SE|2017/09/12 01:00:...| 8.344|https://monitorin...|      2016/11/07|3141062017-09-12 ...|\n",
      "|Calgary Fire Hall...|314106|1212 42 AV SE|2017/09/12 02:00:...|11.703|https://monitorin...|      2016/11/07|3141062017-09-12 ...|\n",
      "+--------------------+------+-------------+--------------------+------+--------------------+----------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_energy.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8174adce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "258423"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_energy.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b52d8ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06df050f",
   "metadata": {},
   "source": [
    "De energie-productie (df_energy_df) dataset bevat 258423 records en de weer-dataset (df_weather) bevat er 10000. Bij 'df_energy' gaan we algemener kijken en groeperen per dag, omdat er helaas geen data per uur terug te vinden was over deze periode. Bij 'df_weather' vallen er nog een heel deel records af die buiten het bereik van 'df_energy' liggen. Zie Cleaning stap 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad174ea",
   "metadata": {},
   "source": [
    "### checken op nullwaardes (missing data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bd6c5458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset bevat geen kolommen met nullwaardes!\n"
     ]
    }
   ],
   "source": [
    "null_columns_e = []\n",
    "\n",
    "for column in df_energy.columns:\n",
    "    if df_energy.filter(col(column).isNull()).count() > 0:\n",
    "        null_columns_e.append(column)\n",
    "\n",
    "if len(null_columns_e) == 0:\n",
    "    print(\"dataset bevat geen kolommen met nullwaardes!\")\n",
    "else:\n",
    "    print(\"dataset bevat kolommen met nullwaardes, namelijk de kolommen:\\n\")\n",
    "    for column_name in null_columns:\n",
    "        print(column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bd34c758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset bevat kolommen met nullwaardes, namelijk de kolommen:\n",
      "\n",
      "max_humidex\n",
      "min_windchill\n",
      "max_wind_gust\n",
      "wind_gust_dir_10s\n",
      "max_health_index\n",
      "avg_hourly_health_index\n",
      "avg_health_index\n",
      "min_health_index\n",
      "precipitation\n",
      "rain\n",
      "snow\n",
      "snow_on_ground\n",
      "sunrise_hhmm\n",
      "sunrise_unixtime\n",
      "sunrise_f\n",
      "sunset_hhmm\n",
      "sunset_unixtime\n",
      "sunset_f\n",
      "daylight\n",
      "min_uv_forecast\n",
      "max_uv_forecast\n",
      "min_high_temperature_forecast\n",
      "max_high_temperature_forecast\n",
      "min_low_temperature_forecast\n",
      "max_low_temperature_forecast\n",
      "solar_radiation\n",
      "max_cloud_cover_4\n",
      "avg_hourly_cloud_cover_4\n",
      "avg_cloud_cover_4\n",
      "min_cloud_cover_4\n",
      "max_cloud_cover_8\n",
      "avg_hourly_cloud_cover_8\n",
      "avg_cloud_cover_8\n",
      "min_cloud_cover_8\n",
      "max_cloud_cover_10\n",
      "avg_hourly_cloud_cover_10\n",
      "avg_cloud_cover_10\n",
      "min_cloud_cover_10\n"
     ]
    }
   ],
   "source": [
    "null_columns_w = []\n",
    "\n",
    "for column in df_weather.columns:\n",
    "    if df_weather.filter(col(column).isNull()).count() > 0:\n",
    "        null_columns_w.append(column)\n",
    "        \n",
    "if len(null_columns_w) == 0:\n",
    "    print(\"dataset bevat geen kolommen met nullwaardes!\")\n",
    "else:\n",
    "    print(\"dataset bevat kolommen met nullwaardes, namelijk de kolommen:\\n\")\n",
    "    for column_name in null_columns_w:\n",
    "          print(column_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fb6146",
   "metadata": {},
   "source": [
    "Gelukkig zijn dit geen kolommen die we later nodig hebben dus vormt het niet meteen een probleem. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64acd3d",
   "metadata": {},
   "source": [
    "### verdeling temperatuur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3d3e21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6deb69b",
   "metadata": {},
   "source": [
    "### verdeling opwekking zonne-energie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfae0865",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "44944a6c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__call__() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [51]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# create schema (checken of nog nodig of niet)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m schema \u001b[38;5;241m=\u001b[39m StructType([\n\u001b[1;32m----> 3\u001b[0m     StructField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mIntegerType\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m      4\u001b[0m     StructField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol2\u001b[39m\u001b[38;5;124m\"\u001b[39m, IntegerType(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m      5\u001b[0m     StructField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol3\u001b[39m\u001b[38;5;124m\"\u001b[39m, IntegerType(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m      6\u001b[0m     StructField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol4\u001b[39m\u001b[38;5;124m\"\u001b[39m, IntegerType(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m      7\u001b[0m     StructField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol5\u001b[39m\u001b[38;5;124m\"\u001b[39m, IntegerType(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m      8\u001b[0m     StructField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol6\u001b[39m\u001b[38;5;124m\"\u001b[39m, IntegerType(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m      9\u001b[0m     StructField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol7\u001b[39m\u001b[38;5;124m\"\u001b[39m, IntegerType(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m     10\u001b[0m     StructField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol8\u001b[39m\u001b[38;5;124m\"\u001b[39m, IntegerType(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m     11\u001b[0m     \n\u001b[0;32m     12\u001b[0m ])\n",
      "\u001b[1;31mTypeError\u001b[0m: __call__() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "# MSS NIET NODIG EN LATER STRUCTUUR IN DATA CREEREN !!! \n",
    "schema = StructType([\n",
    "    StructField(\"col1\", IntegerType(0), True),\n",
    "    StructField(\"col2\", IntegerType(0), True),\n",
    "    StructField(\"col3\", IntegerType(0), True),\n",
    "    StructField(\"col4\", IntegerType(0), True),\n",
    "    StructField(\"col5\", IntegerType(0), True),\n",
    "    StructField(\"col6\", IntegerType(0), True),\n",
    "    StructField(\"col7\", IntegerType(0), True),\n",
    "    StructField(\"col8\", IntegerType(0), True),\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dd12a4f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[PATH_NOT_FOUND] Path does not exist: file:/C:/Users/jarno/SCHOOL Data Presentation/input/airbnbopendata/Airbnb_Open_Data.csv.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [52]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#tests en backup code\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df_energy \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mheader\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minferSchema\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmode\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfailfast\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../input/airbnbopendata/Airbnb_Open_Data.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# csv inladen\u001b[39;00m\n\u001b[0;32m      5\u001b[0m energy \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39mread\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mschema(schema)\u001b[38;5;241m.\u001b[39moption(data_energy, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mload()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyspark\\sql\\readwriter.py:307\u001b[0m, in \u001b[0;36mDataFrameReader.load\u001b[1;34m(self, path, format, schema, **options)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    309\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(path) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mAnalysisException\u001b[0m: [PATH_NOT_FOUND] Path does not exist: file:/C:/Users/jarno/SCHOOL Data Presentation/input/airbnbopendata/Airbnb_Open_Data.csv."
     ]
    }
   ],
   "source": [
    "#tests en backup code\n",
    "df_energy = spark.read.format(\"csv\").option(\"header\",\"true\").option(\"inferSchema\",\"true\").option(\"mode\",\"failfast\").load(\"../input/airbnbopendata/Airbnb_Open_Data.csv\")\n",
    "\n",
    "# csv inladen\n",
    "energy = spark.read.format(\"csv\").schema(schema).option(data_energy, \"test.csv\").load()\n",
    "weather = spark.read.format(\"csv\").schema(schema).option(\"path\", \"test.csv\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbb1a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_weather.select(\"Date\").orderBy(col(\"date\").asc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17afdd3f",
   "metadata": {},
   "source": [
    "## 3 cleaning & preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749ae122",
   "metadata": {},
   "source": [
    "### date kolom aanpassen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c16a79ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                date|\n",
      "+--------------------+\n",
      "|2015/09/01 02:30:...|\n",
      "|2015/09/01 03:30:...|\n",
      "|2015/09/01 04:30:...|\n",
      "|2015/09/01 05:30:...|\n",
      "|2015/09/01 06:30:...|\n",
      "|2015/09/01 07:30:...|\n",
      "|2015/09/01 08:30:...|\n",
      "|2015/09/01 09:30:...|\n",
      "|2015/09/01 10:30:...|\n",
      "|2015/09/01 11:30:...|\n",
      "|2015/09/02 01:30:...|\n",
      "|2015/09/02 01:30:...|\n",
      "|2015/09/02 02:30:...|\n",
      "|2015/09/02 02:30:...|\n",
      "|2015/09/02 03:30:...|\n",
      "|2015/09/02 04:30:...|\n",
      "|2015/09/02 05:30:...|\n",
      "|2015/09/02 06:30:...|\n",
      "|2015/09/02 06:30:...|\n",
      "|2015/09/02 07:30:...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_energy.select(\"date\").orderBy(\"date\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0dc2d9",
   "metadata": {},
   "source": [
    "df_energy datums nog omzetten (casten) naar een date want staat oorspronkelijk in het unixtime formaat met `yyyy/MM/dd hh:mm:ss a`en er moet iets van het type date `yyyy/MM/dd` bekomen worden zoals we in de df_weather hebben. Zo kan de data later worden samengevoegd op basis van gelijke datums."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8356b775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|     date2|\n",
      "+----------+\n",
      "|2017-09-11|\n",
      "|2017-09-11|\n",
      "|2017-09-11|\n",
      "|2017-09-11|\n",
      "|2017-09-11|\n",
      "|2017-09-11|\n",
      "|2017-09-11|\n",
      "|2017-09-11|\n",
      "|2017-09-11|\n",
      "|2017-09-11|\n",
      "|2017-09-11|\n",
      "|2017-09-11|\n",
      "|2017-09-12|\n",
      "|2017-09-12|\n",
      "|2017-09-12|\n",
      "|2017-09-12|\n",
      "|2017-09-12|\n",
      "|2017-09-12|\n",
      "|2017-09-12|\n",
      "|2017-09-12|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_energy = df_energy.withColumn(\"date2\", from_unixtime(unix_timestamp(col(\"date\"), 'yyyy/MM/dd hh:mm:ss a')).cast(\"date\"))\n",
    "\n",
    "df_energy.select(\"date2\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf180a0",
   "metadata": {},
   "source": [
    "### data uit df_energy groeperen per dag\n",
    "Er wordt verder gerekend met de gemiddelde kWh per dag in df_energy, gezien we niet van elk uur weerdata ter beschikking hebben.\n",
    "Zoals we ook al bij het inladen konden zien bevat df_energy 258423 rijen (omdat er meerdere metingen zijn per dag) en df_weather 10000 rijen, per dag 1 record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b392902c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n",
      "|     date2|          avg(kWh)|\n",
      "+----------+------------------+\n",
      "|2015-09-01|28.601300000000002|\n",
      "|2015-09-02| 32.45933333333333|\n",
      "|2015-09-03|30.852666666666657|\n",
      "|2015-09-04|            5.1224|\n",
      "|2015-09-05|4.9174736842105276|\n",
      "|2015-09-06|           18.3813|\n",
      "|2015-09-07|30.262947368421052|\n",
      "|2015-09-08|           24.4907|\n",
      "|2015-09-09|           36.6001|\n",
      "|2015-09-10|  33.0881052631579|\n",
      "|2015-09-11| 45.54736842105263|\n",
      "|2015-09-12| 44.59063157894737|\n",
      "|2015-09-13|13.285210526315788|\n",
      "|2015-09-14|  5.36278947368421|\n",
      "|2015-09-15| 32.56542105263158|\n",
      "|2015-09-16| 35.77613333333333|\n",
      "|2015-09-17| 50.94357142857143|\n",
      "|2015-09-18| 50.00066666666666|\n",
      "|2015-09-21| 45.08325000000001|\n",
      "|2015-09-22|60.640538461538455|\n",
      "+----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_energy = df_energy.withColumn(\"date2\", from_unixtime(unix_timestamp(col(\"date\"), 'yyyy/MM/dd hh:mm:ss a')).cast(\"date\"))\n",
    "# groepeer per dag en bereken average temperature per dag\n",
    "df_energy_day = df_energy.groupBy(\"date2\").agg({\"kWh\": \"avg\"}).orderBy(\"date2\")#.show() returnt een NoneType, hierdoor kan er later nioet mee gewerkt worden! \n",
    "\n",
    "df_energy_day.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed7fad1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_energy_day.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c371129c",
   "metadata": {},
   "source": [
    "### data buiten bereik filteren\n",
    "Dagen uit df_weather verwijderen die buiten het bereik van df_energy vallen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72b955ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum datum uit df_weather is: 1996-07-13\n",
      "Maximum datum uit df_weather is: 2023-11-28\n",
      "Minimum datum uit df_energy_day is: 2015-09-01\n",
      "Maximum datum uit df_energy_day is: 2023-03-16\n",
      "\n",
      "Aantal overgebleven records uit df_energy na groepering per dag is: 2716\n",
      "Aantal records uit df_weather is: 10000\n"
     ]
    }
   ],
   "source": [
    "# temp table\n",
    "df_weather.createOrReplaceTempView(\"weather_table\")\n",
    "df_energy_day.createOrReplaceTempView(\"energy_table\")\n",
    "\n",
    "#SQL queries\n",
    "query_w = \"\"\"\n",
    "    SELECT\n",
    "        MIN(CAST(date AS DATE)) AS min_date,\n",
    "        MAX(CAST(date AS DATE)) AS max_date\n",
    "    FROM\n",
    "        weather_table\n",
    "\"\"\"\n",
    "\n",
    "query_e = \"\"\"\n",
    "    SELECT\n",
    "        MIN(CAST(date2 AS DATE)) AS min_date,\n",
    "        MAX(CAST(date2 AS DATE)) AS max_date\n",
    "    FROM\n",
    "        energy_table\n",
    "\"\"\"\n",
    "\n",
    "# Execute SQL\n",
    "date_min_max_w = spark.sql(query_w).first()\n",
    "date_min_max_e = spark.sql(query_e).first()\n",
    "\n",
    "min_date_w = date_min_max_w.min_date\n",
    "max_date_w = date_min_max_w.max_date\n",
    "min_date_e = date_min_max_e.min_date\n",
    "max_date_e = date_min_max_e.max_date\n",
    "\n",
    "records_df_energy = df_energy_day.count()\n",
    "records_df_weather = df_weather.count()\n",
    "\n",
    "print(f\"Minimum datum uit df_weather is: {min_date_w}\")\n",
    "print(f\"Maximum datum uit df_weather is: {max_date_w}\")\n",
    "print(f\"Minimum datum uit df_energy_day is: {min_date_e}\")\n",
    "print(f\"Maximum datum uit df_energy_day is: {max_date_e}\")\n",
    "print(f\"\\nAantal overgebleven records uit df_energy na groepering per dag is: {records_df_energy}\")\n",
    "print(f\"Aantal records uit df_weather is: {records_df_weather}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dd7b3a",
   "metadata": {},
   "source": [
    "Nu zijn er meer 'weather' records dan 'energy' records en moet de data buiten het bereik van van de dagen waarvoor er energie-data is, uitgefilterd worden.\n",
    "\n",
    "Er hoeft niet speciaal nog een drop operatie gedaan worden om de data te verwijderen die niet matcht aangezien er later nog gejoind zal worden en de data die overeenkomt automatisch overgehouden wordt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc893d6",
   "metadata": {},
   "source": [
    "### niet-relevante kolommen uitfilteren"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68988c60",
   "metadata": {},
   "source": [
    "Voor dit project zijn we enkel geinteresseerd in de `avg_temperature` kolom uit `df_weather`. Natuurlijk zijn er heel wat andere kolommen die ook invloed hebben op de energieproductie van zonnepanelen maar we willen juist de correlatie bespreken tussen een warme dag of een koude dag en de daarbij horende energie opwekking.\n",
    "\n",
    "er zijn een paar kolommen kandidaat: TODO nog uitzoeken welke!!!! ####\n",
    "- avg_cloud_cover_4\n",
    "- avg_cloud_cover_8\n",
    "- avg_cloud_cover_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a416a312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, max_temperature: string, avg_hourly_temperature: string, avg_temperature: string, min_temperature: string, max_humidex: string, min_windchill: string, max_relative_humidity: string, avg_hourly_relative_humidity: string, avg_relative_humidity: string, min_relative_humidity: string, max_dew_point: string, avg_hourly_dew_point: string, avg_dew_point: string, min_dew_point: string, max_wind_speed: string, avg_hourly_wind_speed: string, avg_wind_speed: string, min_wind_speed: string, max_wind_gust: string, wind_gust_dir_10s: string, max_pressure_sea: string, avg_hourly_pressure_sea: string, avg_pressure_sea: string, min_pressure_sea: string, max_pressure_station: string, avg_hourly_pressure_station: string, avg_pressure_station: string, min_pressure_station: string, max_visibility: string, avg_hourly_visibility: string, avg_visibility: string, min_visibility: string, max_health_index: string, avg_hourly_health_index: string, avg_health_index: string, min_health_index: string, heatdegdays: string, cooldegdays: string, growdegdays_5: string, growdegdays_7: string, growdegdays_10: string, precipitation: string, rain: string, snow: string, snow_on_ground: string, sunrise_unixtime: string, sunrise_f: string, sunset_unixtime: string, sunset_f: string, daylight: string, min_uv_forecast: string, max_uv_forecast: string, min_high_temperature_forecast: string, max_high_temperature_forecast: string, min_low_temperature_forecast: string, max_low_temperature_forecast: string, solar_radiation: string, max_cloud_cover_4: string, avg_hourly_cloud_cover_4: string, avg_cloud_cover_4: string, min_cloud_cover_4: string, max_cloud_cover_8: string, avg_hourly_cloud_cover_8: string, avg_cloud_cover_8: string, min_cloud_cover_8: string, max_cloud_cover_10: string, avg_hourly_cloud_cover_10: string, avg_cloud_cover_10: string, min_cloud_cover_10: string]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "abbe9fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kolommen die we niet nodig hebben uitfilteren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02df118b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather_selected_col = df_weather.select(\"date\", \"avg_temperature\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4b351d",
   "metadata": {},
   "source": [
    "### joinen op basis van datum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3443c06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+---------------+\n",
      "|     date2|          avg(kWh)|avg_temperature|\n",
      "+----------+------------------+---------------+\n",
      "|2015-09-01|28.601300000000002|          14.64|\n",
      "|2015-09-02| 32.45933333333333|          15.45|\n",
      "|2015-09-03|30.852666666666657|           9.19|\n",
      "|2015-09-04|            5.1224|           5.69|\n",
      "|2015-09-05|4.9174736842105276|            3.7|\n",
      "|2015-09-06|           18.3813|            5.0|\n",
      "|2015-09-07|30.262947368421052|           9.94|\n",
      "|2015-09-08|           24.4907|           10.8|\n",
      "|2015-09-09|           36.6001|           13.3|\n",
      "|2015-09-10|  33.0881052631579|           12.1|\n",
      "|2015-09-11| 45.54736842105263|           16.8|\n",
      "|2015-09-12| 44.59063157894737|          19.14|\n",
      "|2015-09-13|13.285210526315788|          10.15|\n",
      "|2015-09-14|  5.36278947368421|            5.9|\n",
      "|2015-09-15| 32.56542105263158|           8.55|\n",
      "|2015-09-16| 35.77613333333333|            7.0|\n",
      "|2015-09-17| 50.94357142857143|           8.15|\n",
      "|2015-09-18| 50.00066666666666|          11.35|\n",
      "|2015-09-21| 45.08325000000001|            5.3|\n",
      "|2015-09-22|60.640538461538455|          11.05|\n",
      "+----------+------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Alias\n",
    "energy = df_energy_day.alias(\"df_energy_day\")\n",
    "weer = df_weather_selected_col.alias(\"df_weather\")\n",
    "\n",
    "# inner join on 'date' kolom\n",
    "joined_df = energy.join(weer, energy['date2'] == weer['Date'], 'left')\n",
    "\n",
    "joined_df.select(energy['date2'], energy['avg(kWh)'], weer['avg_temperature']).orderBy(\"date2\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fd546ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we hebben nu 2 datum kolommen dus 1tje mag verwijderd worden\n",
    "joined_df = joined_df.drop(col(\"date2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81cd3e22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2716"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be96605f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------+---------------+\n",
      "|          avg(kWh)|      date|avg_temperature|\n",
      "+------------------+----------+---------------+\n",
      "|34.126020833333335|2017-09-11|          18.64|\n",
      "| 61.16932075471698|2017-08-11|           18.7|\n",
      "| 42.58591666666667|2016-03-01|          -0.59|\n",
      "|61.045993464052316|2019-06-04|           16.0|\n",
      "|           66.2803|2018-05-28|           20.0|\n",
      "| 54.34225641025642|2018-08-10|          26.15|\n",
      "| 53.71429411764706|2021-06-22|           21.6|\n",
      "| 48.74009210526314|2019-05-08|           7.25|\n",
      "|37.910468468468466|2021-10-11|           0.95|\n",
      "|62.834886666666655|2020-08-24|          20.25|\n",
      "|1.8028571428571432|2021-12-18|          -9.19|\n",
      "| 23.22218681318681|2021-11-13|           3.45|\n",
      "| 3.548602564102563|2021-01-27|          -13.2|\n",
      "|  32.0981971830986|2021-08-27|          15.45|\n",
      "| 34.12024615384616|2022-03-28|           0.59|\n",
      "|53.465215277777766|2022-07-31|          21.65|\n",
      "|14.803142857142856|2016-04-25|            3.8|\n",
      "|27.433728260869565|2019-11-18|           5.15|\n",
      "| 52.27623148148149|2019-11-01|           0.75|\n",
      "|20.049341666666667|2018-03-17|           -1.1|\n",
      "+------------------+----------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joined_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1a92da",
   "metadata": {},
   "source": [
    "### datatypes toekennen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c59e5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: avg(kWh), Data Type: double\n",
      "Column: date, Data Type: date\n",
      "Column: avg_temperature, Data Type: double\n"
     ]
    }
   ],
   "source": [
    "column_data_types = joined_df.dtypes\n",
    "\n",
    "for column, data_type in column_data_types:\n",
    "    print(f\"Column: {column}, Data Type: {data_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2dc133",
   "metadata": {},
   "source": [
    "Zo te zien bevat deze dataframe al automatisch de juiste datatypes om mee aan de slag te gaan. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c646d9",
   "metadata": {},
   "source": [
    "## Visualisatie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42079f85",
   "metadata": {},
   "source": [
    "TODO ####  mooie grafiek met plot en VERWACHT.... winter zomer duidelijk aflezen\n",
    "evt met widgets,..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700b759e",
   "metadata": {},
   "source": [
    "TODO #### corelatie aantonen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6e7f3e",
   "metadata": {},
   "source": [
    "## Conclusie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c720b9d",
   "metadata": {},
   "source": [
    "Andere kolommen waarvan de productie zeker afhaneklijk is: \n",
    "\n",
    "----\n",
    "max visibility\n",
    "preciptation/rain/snow en vooral snow_on_ground\n",
    "solar_radiation\n",
    "sunrise-sunset\n",
    "daylight"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
